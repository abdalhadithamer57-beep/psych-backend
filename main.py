import os
import sqlite3
from dotenv import load_dotenv
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
from langchain_openai import ChatOpenAI

load_dotenv()
app = FastAPI()

# ╪е╪╣╪п╪з╪п CORS ┘Д┘Д╪│┘Е╪з╪н ╪и╪з┘Д╪з╪к╪╡╪з┘Д ┘Е┘Ж ╪г┘К ╪м┘З╪з╪▓ (┘Е┘З┘Е ┘Д╪к╪м╪▒╪и╪й ╪з┘Д╪м┘И╪з┘Д)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ╪е╪╣╪п╪з╪п ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ---
def get_db_connection():
    # ┘Ж╪╢╪╣ ╪з┘Д┘Е╪н╪з╪п╪л╪з╪к ┘Б┘К ┘Е┘Д┘Б sqlite ┘Е╪н┘Д┘К
    conn = sqlite3.connect('psych_consultant.db', check_same_thread=False)
    conn.row_factory = sqlite3.Row
    return conn

def init_db():
    conn = get_db_connection()
    conn.execute('''CREATE TABLE IF NOT EXISTS messages 
                    (user_id TEXT, role TEXT, content TEXT, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)''')
    conn.commit()
    conn.close()

init_db()

# --- ╪е╪╣╪п╪з╪п ┘Е╪н╪▒┘Г ╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д┘Е┘Д┘Б╪з╪к (PDF) ---
# ┘Ж╪│╪к╪о╪п┘Е ┘Ж┘Е┘И╪░╪м ┘К╪п╪╣┘Е ╪з┘Д╪╣╪▒╪и┘К╪й ╪и╪з┘Е╪к┘К╪з╪▓
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

def build_vector_db():
    path = "./knowledge_base/"
    if not os.path.exists(path): 
        os.makedirs(path)
        return None
    
    loader = PyPDFDirectoryLoader(path)
    documents = loader.load()
    if not documents: 
        print("тЪая╕П ┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ┘Е┘Д┘Б╪з╪к PDF ┘Б┘К ┘Е╪м┘Д╪п knowledge_base")
        return None
    
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)
    splits = text_splitter.split_documents(documents)
    return FAISS.from_documents(splits, embeddings)

db = build_vector_db()

GROQ_KEY = os.getenv("GROQ_API_KEY")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")

@app.post("/chat")
async def chat_endpoint(request: Request):
    try:
        data = await request.json()
        user_query = data.get("message", "")
        # ╪з╪│╪к┘Д╪з┘Е user_id ╪з┘Д┘Е╪▒╪│┘Д ┘Е┘Ж ╪з┘Д┘И╪з╪м┘З╪й ╪з┘Д╪г┘Е╪з┘Е┘К╪й
        user_id = data.get("user_id", "guest_user") 

        # 1. ┘Б╪н╪╡ ┘Г┘Д┘Е╪з╪к ╪з┘Д╪╖┘И╪з╪▒╪ж (╪з┘Д╪г┘Е╪з┘Ж)
        safety_words = ["╪з┘Ж╪к╪н╪з╪▒", "╪е┘К╪░╪з╪б", "╪г┘В╪к┘Д ┘Ж┘Б╪│┘К", "╪з┘Ж╪к╪н╪▒", "╪г┘Ж┘З┘К ╪н┘К╪з╪к┘К"]
        if any(word in user_query for word in safety_words):
            emergency_msg = "╪г┘Ж╪з ╪г┘З╪к┘Е ┘Д╪г┘Е╪▒┘Г ╪м╪п╪з┘Л. ┘К╪и╪п┘И ╪г┘Ж┘Г ╪к┘Е╪▒ ╪и┘И┘В╪к ╪╡╪╣╪и ┘Д┘Д╪║╪з┘К╪й. ┘Е┘Ж ┘Б╪╢┘Д┘Г╪М ╪к┘И╪з╪╡┘Д ┘Е╪╣ ╪з┘Д┘Е╪о╪к╪╡┘К┘Ж ┘Б┘И╪▒╪з┘Л ╪г┘И ╪з╪к╪╡┘Д ╪и╪о╪╖ ╪з┘Д┘Е╪│╪з╪╣╪п╪й 911. ╪г┘Ж╪к ┘Д╪│╪к ┘И╪н╪п┘Г ┘И┘З┘Ж╪з┘Г ╪п╪з╪ж┘Е╪з┘Л ╪г┘Е┘Д."
            return {
                "response": emergency_msg, 
                "source": "ЁЯЪи ┘Ж╪╕╪з┘Е ╪з┘Д╪н┘Е╪з┘К╪й ╪з┘Д╪╖╪з╪▒╪ж",
                "isEmergency": True
            }

        # 2. ╪н┘Б╪╕ ╪▒╪│╪з┘Д╪й ╪з┘Д┘Е╪│╪к╪о╪п┘Е ┘Б┘К ╪з┘Д┘В╪з╪╣╪п╪й
        conn = get_db_connection()
        conn.execute("INSERT INTO messages (user_id, role, content) VALUES (?, ?, ?)", 
                     (user_id, "user", user_query))
        conn.commit()

        # 3. ╪м┘Д╪и ╪в╪о╪▒ 6 ╪▒╪│╪з╪ж┘Д ┘Б┘В╪╖ ┘Д╪и┘Ж╪з╪б ╪│┘К╪з┘В ╪░┘Г┘К (Memory)
        past_msgs = conn.execute("SELECT role, content FROM messages WHERE user_id = ? ORDER BY rowid DESC LIMIT 6", 
                                 (user_id,)).fetchall()
        
        memory_text = ""
        for msg in reversed(past_msgs):
            role_label = "╪з┘Д┘Е╪│╪к╪о╪п┘Е" if msg['role'] == 'user' else "╪з┘Д┘Е╪│╪к╪┤╪з╪▒"
            memory_text += f"{role_label}: {msg['content']}\n"

        # 4. ╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д┘Е┘Д┘Б╪з╪к ╪з┘Д╪╣┘Д┘Е┘К╪й (RAG)
        context = ""
        if db:
            try:
                docs = db.similarity_search(user_query, k=3)
                context = "\n".join([d.page_content for d in docs])
            except Exception as e:
                print(f"Search Error: {e}")

        # 5. ╪╡┘К╪з╪║╪й ╪з┘Д╪к╪╣┘Д┘К┘Е╪з╪к ╪з┘Д┘Ж┘З╪з╪ж┘К╪й ┘Д┘Д┘Е┘И╪п┘К┘Д
        system_instruction = f"""
        ╪г┘Ж╪к ┘Е╪│╪к╪┤╪з╪▒ ┘Ж┘Б╪│┘К ╪п╪з┘Б╪ж╪М ┘Е╪к╪╣╪з╪╖┘Б╪М ┘И┘Е┘З┘Ж┘К ╪м╪п╪з┘Л. 
        ╪к╪│╪к╪о╪п┘Е ┘Е┘З╪з╪▒╪з╪к ╪з┘Д╪з╪│╪к┘Е╪з╪╣ ╪з┘Д┘Ж╪┤╪╖ ┘И╪з┘Д╪░┘Г╪з╪б ╪з┘Д╪╣╪з╪╖┘Б┘К.
        
        ╪│┘К╪з┘В ╪з┘Д┘Е╪н╪з╪п╪л╪й ╪з┘Д╪│╪з╪и┘В╪й:
        {memory_text}

        ┘Е╪▒╪з╪м╪╣ ╪╣┘Д┘Е┘К╪й ┘Е╪│╪з╪╣╪п╪й (╪з╪│╪к╪о╪п┘Е┘З╪з ╪и╪░┘Г╪з╪б):
        {context}
        
        ╪г╪м╪и ╪и╪з┘Д┘Д╪║╪й ╪з┘Д╪╣╪▒╪и┘К╪й ╪и╪г╪│┘Д┘И╪и ╪и╪│┘К╪╖ ┘И┘З╪з╪п╪ж. ┘Д╪з ╪к┘В╪п┘Е ╪к╪┤╪о┘К╪╡╪з╪к ╪╖╪и┘К╪й ┘Ж┘З╪з╪ж┘К╪й╪М ╪и┘Д ┘В╪п┘Е ╪п╪╣┘Е╪з┘Л ┘И╪е╪▒╪┤╪з╪п╪з┘Л.
        """
        
        # 6. ┘Е┘Ж╪╖┘В ╪з┘Д╪к╪и╪п┘К┘Д ╪з┘Д╪к┘Д┘В╪з╪ж┘К (Failover)
        final_response = ""
        badge = "╪з╪│╪к╪┤╪з╪▒╪й ╪░┘Г┘К╪й"
        
        try:
            # ╪з┘Д╪о┘К╪з╪▒ ╪з┘Д╪г┘И┘Д: Groq (╪│╪▒┘К╪╣ ╪м╪п╪з┘Л)
            llm = ChatGroq(temperature=0.4, model_name="llama-3.1-8b-instant", groq_api_key=GROQ_KEY)
            response = llm.invoke([
                {"role": "system", "content": system_instruction},
                {"role": "user", "content": user_query}
            ])
            final_response = response.content
        except Exception as e:
            print(f"Groq failed: {e}. Switching to OpenAI...")
            try:
                # ╪з┘Д╪о┘К╪з╪▒ ╪з┘Д╪л╪з┘Ж┘К: OpenAI (╪п┘В┘К┘В ╪м╪п╪з┘Л)
                llm_backup = ChatOpenAI(model_name="gpt-4o-mini", openai_api_key=OPENAI_KEY)
                response = llm_backup.invoke([
                    {"role": "system", "content": system_instruction},
                    {"role": "user", "content": user_query}
                ])
                final_response = response.content
                badge = "╪з╪│╪к╪┤╪з╪▒╪й ╪з╪н╪к┘К╪з╪╖┘К╪й"
            except:
                final_response = "╪╣╪░╪▒╪з┘Л╪М ╪г┘И╪з╪м┘З ╪╢╪║╪╖╪з┘Л ╪к┘В┘Ж┘К╪з┘Л ╪н╪з┘Д┘К╪з┘Л. ┘З┘Д ┘К┘Е┘Г┘Ж┘Г ╪з┘Д┘Е╪н╪з┘И┘Д╪й ┘Е╪▒╪й ╪г╪о╪▒┘Й ╪и╪╣╪п ┘Д╪н╪╕╪з╪к╪Я"

        # 7. ╪н┘Б╪╕ ╪▒╪п ╪з┘Д┘Е╪│╪к╪┤╪з╪▒ ┘Б┘К ╪з┘Д┘В╪з╪╣╪п╪й ┘Д╪к╪░┘Г╪▒┘З ┘Е╪│╪к┘В╪и┘Д╪з┘Л
        conn.execute("INSERT INTO messages (user_id, role, content) VALUES (?, ?, ?)", 
                     (user_id, "assistant", final_response))
        conn.commit()
        conn.close()

        return {
            "response": final_response, 
            "source": badge, 
            "isEmergency": False
        }

    except Exception as e:
        print(f"Endpoint Error: {e}")
        return {"response": "╪н╪п╪л ╪о╪╖╪г ╪к┘В┘Ж┘К ╪║┘К╪▒ ┘Е╪к┘И┘В╪╣.", "error": True}